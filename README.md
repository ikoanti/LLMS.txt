# LLMS.txt

## What is llms.txt?

llms.txt is a new file (similar in purpose to robots.txt) used to declare a websiteâ€™s policy toward Large Language Models (LLMs) like ChatGPT, Bard, Claude, etc. It tells AI crawlers whether they are allowed to crawl and use your site content for training or not.

## File Creation Instructions

### Create the file locally:

Open a plain text editor (like Notepad, VS Code, Sublime Text).

Paste the preferred version of the llms.txt content.

Save the file as llms.txt.

### Upload to your website:

Log in to your hosting provider or use an FTP client (like FileZilla).

Go to the root directory of your domain (commonly called public_html, /var/www/html/, or /htdocs/).

Place the llms.txt file in this root directory.

## Tips

llms.txt is not yet a legally binding or universally respected standard, but it is increasingly being honored by companies building responsible AI systems.

Combining this file with legal Terms of Service and robots.txt can help reinforce your content policy.
